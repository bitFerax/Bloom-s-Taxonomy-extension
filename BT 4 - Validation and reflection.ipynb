{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "BT 4 - Validation and reflection.ipynb\n",
    "Author: Jingchuan Shi\n",
    "Acknowledgments: Asst. Prof. Ahmed Qureshi\n",
    "Created 2019/9/10, last modified 2019/9/14 at University of Alberta.\n",
    "All Rights Reserved.\n",
    "'''\n",
    "\n",
    "# Load relevant modules.\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_vectors\") # Model en_vectors_web_lg of SpaCy with a pre-defined shortcut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of verbs pre-labelled with corresponding Bloom's Taxonomy domains.\n",
    "knowledge_words = ['list', 'name', 'define', 'repeat', 'state', 'label', 'recall', 'identify', 'reproduce', 'describe', 'recognize', 'select', 'record', 'match', 'relate', 'memorize', 'outline', 'quote', 'enumerate', 'write', 'tell', 'recite', 'cite', 'duplicate', 'read', 'order', 'tabulate', 'draw', 'review', 'indicate', 'underline', 'arrange', 'know', 'point', 'count', 'collect', 'meet', 'study', 'trace', 'find', 'index', 'locate', 'show', 'visualize', 'examine', 'copy', 'sequence', 'acquire', 'retell', 'view', 'observe', 'tally', 'imitate', 'follow']\n",
    "comprehension_words = ['explain', 'describe', 'discuss', 'paraphrase', 'restate', 'summarize', 'translate', 'convert', 'review', 'express', 'estimate', 'identify', 'generalize', 'interpret', 'locate', 'give', 'distinguish', 'extend', 'predict', 'recognize', 'defend', 'classify', 'infer', 'report', 'illustrate', 'rewrite', 'select', 'contrast', 'differentiate', 'compare', 'indicate', 'exemplify', 'observe', 'elaborate', 'associate', 'visualize', 'articulate', 'clarify', 'subtract', 'approximate', 'interpolate', 'tell', 'detail', 'outline', 'cite', 'picture', 'interact', 'conclude', 'characterize', 'add', 'factor', 'compute', 'match', 'schedule', 'order', 'sketch', 'draw', 'define', 'operate', 'arrange', 'group', 'extrapolate', 'diagram', 'interrelate', 'represent', 'trace', 'shop', 'suggest', 'understand']\n",
    "application_words = ['demonstrate', 'use', 'apply', 'solve', 'illustrate', 'dramatize', 'practise', 'employ', 'operate', 'sketch', 'prepare', 'show', 'compute', 'relate', 'construct', 'interpret', 'discover', 'change', 'produce', 'manipulate', 'schedule', 'modify', 'predict', 'complete', 'choose', 'classify', 'translate', 'determine', 'examine', 'calculate', 'investigate', 'draw', 'write', 'protect', 'derive', 'chart', 'alphabetize', 'simulate', 'process', 'provide', 'capture', 'project', 'transcribe', 'organize', 'shop', 'establish', 'attain', 'graph', 'assign', 'allocate', 'convert', 'experiment', 'exercise', 'diminish', 'make', 'develop', 'ascertain', 'tabulate', 'depreciate', 'subscribe', 'implement', 'handle', 'transfer', 'factor', 'avoid', 'expose', 'express', 'perform', 'sequence', 'acquire', 'administer', 'personalize', 'adapt', 'plot', 'customize', 'interview', 'paint', 'explore', 'utilize', 'report', 'figure', 'price', 'coordinate', 'simplify', 'consult', 'maintain', 'deliver', 'extend', 'imitate', 'guide', 'conduct', 'multiply', 'build', 'code', 'contribute', 'obtain', 'model', 'compare', 'divide', 'exhibit', 'tally', 'inform', 'diagram', 'expand', 'amend', 'engineer', 'control', 'assess', 'concatenate', 'execute', 'convey', 'articulate', 'restructure', 'criticize', 'appraise', 'participate', 'generalize', 'instruct', 'follow', 'act', 'screen', 'debate', 'question', 'select', 'include', 'dissect', 'retrieve', 'inspect', 'prove', 'inventory', 'respond', 'comply', 'collect']\n",
    "analysis_words = ['compare', 'contrast', 'distinguish', 'analyze', 'differentiate', 'separate', 'examine', 'diagram', 'infer', 'categorize', 'experiment', 'discriminate', 'select', 'appraise', 'relate', 'test', 'question', 'classify', 'identify', 'outline', 'illustrate', 'subdivide', 'investigate', 'debate', 'criticize', 'calculate', 'inventory', 'prioritize', 'correlate', 'explain', 'inspect', 'detect', 'dissect', 'manage', 'audit', 'characterize', 'order', 'deduce', 'limit', 'connect', 'diagnose', 'document', 'proofread', 'discover', 'ensure', 'optimize', 'maximize', 'confirm', 'divide', 'transform', 'figure', 'prepare', 'file', 'determine', 'train', 'solve', 'survey', 'group', 'minimize', 'interrupt', 'explore', 'blueprint', 'arrange', 'query', 'edit', 'prove', 'isolate', 'reconcile', 'troubleshoot', 'sketch', 'create', 'summarize', 'dramatize', 'employ', 'inquire', 'link', 'abstract', 'establish', 'organize', 'compute', 'devise', 'moderate', 'delegate', 'research', 'model', 'practise', 'operate', 'demonstrate', 'schedule', 'check', 'use', 'chunk', 'choose', 'scrutinize', 'chart', 'apply', 'allow', 'extrapolate', 'recognize', 'show', 'modify', 'administer', 'review', 'change', 'monitor', 'direct', 'corroborate', 'produce', 'negotiate', 'probe', 'accept', 'design', 'interpret', 'extract', 'manipulate', 'focus', 'write', 'predict', 'resolve']\n",
    "synthesis_words = ['design', 'create', 'formulate', 'plan', 'compose', 'construct', 'develop', 'combine', 'assemble', 'propose', 'devise', 'arrange', 'organize', 'collect', 'rearrange', 'prepare', 'reconstruct', 'invent', 'generate', 'modify', 'write', 'categorize', 'rewrite', 'relate', 'compile', 'revise', 'reorganize', 'summarize', 'manage', 'generalize', 'integrate', 'explain', 'produce', 'originate', 'tell', 'incorporate', 'facilitate', 'hypothesize', 'substitute', 'specify', 'improve', 'format', 'correspond', 'model', 'depict', 'synthesize', 'refer', 'comply', 'enhance', 'import', 'overhaul', 'animate', 'predict', 'adapt', 'cultivate', 'code', 'join', 'handle', 'anticipate', 'portray', 'express', 'budget', 'cope', 'debug', 'perform', 'communicate', 'outline', 'prescribe', 'initiate', 'network', 'program', 'lecture', 'dictate', 'advise', 'document', 'gather', 'derive', 'abstract', 'expand', 'establish', 'collaborate', 'conduct', 'contribute', 'coordinate', 'compare', 'speculate', 'simulate', 'progress', 'forecast', 'instruct', 'structure', 'intervene', 'frame', 'measure', 'estimate', 'recommend', 'negotiate', 'consolidate', 'choose', 'contrast', 'imagine', 'individualize', 'recognize', 'solve', 'roleplay', 'review', 'arbitrate', 'teach', 'supervise', 'assess', 'counsel', 'exchange', 'brief', 'reinforce', 'unify', 'pretend', 'update', 'validate']\n",
    "evaluation_words = ['judge', 'appraise', 'evaluate', 'support', 'assess', 'select', 'justify', 'compare', 'rate', 'conclude', 'value', 'defend', 'estimate', 'choose', 'critique', 'argue', 'measure', 'recommend', 'discriminate', 'decide', 'interpret', 'criticize', 'contrast', 'rank', 'predict', 'explain', 'summarize', 'score', 'grade', 'revise', 'relate', 'verify', 'test', 'validate', 'attach', 'determine', 'describe', 'convince', 'prescribe', 'consider', 'release', 'counsel', 'hire', 'prioritize', 'deduce', 'enforce', 'advise', 'motivate', 'core', 'uphold', 'resolve', 'reconcile', 'discuss', 'authenticate', 'review', 'monitor', 'weigh', 'debate', 'diagnose', 'infer', 'mediate', 'prove', 'use', 'preserve', 'access', 'consolidate']\n",
    "wordlists = [knowledge_words, comprehension_words, application_words, analysis_words, synthesis_words, evaluation_words]\n",
    "namelist = ['knowledge', 'comprehension', 'application', 'analysis', 'synthesis', 'evaluation']\n",
    "# Paths to related input and output files. Please modify the master path to your own.\n",
    "master_path = '/Users/ferax/bin/'\n",
    "result_path = master_path + 'BTresult_verify.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization.\n",
    "result = {}\n",
    "total = 0\n",
    "subtotals = [0 for i in range(6)]\n",
    "prob_matrix = [[0 for i in range(6)] for j in range(6)]\n",
    "# Load classification results.\n",
    "with open(result_path, 'r') as rf:\n",
    "    for line in rf.readlines():\n",
    "        tokens = line.replace('\\n', '').split(' ')\n",
    "        result[tokens[0]] = {'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': 0}\n",
    "        total += 1\n",
    "        for i in range(6):\n",
    "            if str(i) in tokens[1:]:\n",
    "                result[tokens[0]][str(i)] = 1\n",
    "                subtotals[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average / Max / Min of mutual influence for cognitive levels at distance k:\n",
      "k = 1: 0.818 1.532 0.452\n",
      "k = 2: 1.075 1.783 0.485\n",
      "k = 3: 0.494 0.716 0.347\n",
      "k = 4: 0.861 1.327 0.396\n",
      "k = 5: 0.678 0.678 0.678\n",
      "\n",
      "Mutual influence matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[None, 1.532, 0.485, 0.716, 0.396, 0.678],\n",
       " [1.532, None, 0.618, 1.783, 0.347, 1.327],\n",
       " [0.485, 0.618, None, 0.697, 0.928, 0.419],\n",
       " [0.716, 1.783, 0.697, None, 0.793, 1.102],\n",
       " [0.396, 0.347, 0.928, 0.793, None, 0.452],\n",
       " [0.678, 1.327, 0.419, 1.102, 0.452, None]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computation of mutual influence, defined as how more or less likely a word is going to belong to a certain domain, D_j, given that it already belongs to D_i.\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if i == j:\n",
    "            prob_matrix[i][j] = None\n",
    "        else:\n",
    "            count_ij = 0\n",
    "            for word in list(result.keys()):\n",
    "                if result[word][str(i)] and result[word][str(j)]:\n",
    "                    count_ij += 1\n",
    "            prob_matrix[i][j] = round((count_ij * total) / (subtotals[i] * subtotals[j]), 3)\n",
    "d = [[0 for j in range(3)] for i in range(5)] #Mean / max / min mutual influence between all the domains at distance k in the original taxonomy.\n",
    "for i in range(5):\n",
    "    for j in range(5 - i):\n",
    "        d[i][0] += prob_matrix[j][i + j + 1]\n",
    "        if j == 0:\n",
    "            d[i][1] = prob_matrix[j][j + i + 1]\n",
    "            d[i][2] = prob_matrix[j][j + i + 1]\n",
    "        else:\n",
    "            d[i][1] = max(d[i][1], prob_matrix[j][j + i + 1])\n",
    "            d[i][2] = min(d[i][2], prob_matrix[j][j + i + 1])\n",
    "    d[i][0] /= 5 - i\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "        d[i][j] = round(d[i][j], 3)\n",
    "\n",
    "# Presentation of results.\n",
    "print('Average / Max / Min of mutual influence for cognitive levels at distance k:')\n",
    "print('k = 1: ', end = '')\n",
    "print(d[0][0], d[0][1], d[0][2])\n",
    "print('k = 2: ', end = '')\n",
    "print(d[1][0], d[1][1], d[1][2])\n",
    "print('k = 3: ', end = '')\n",
    "print(d[2][0], d[2][1], d[2][2])\n",
    "print('k = 4: ', end = '')\n",
    "print(d[3][0], d[3][1], d[3][2])\n",
    "print('k = 5: ', end = '')\n",
    "print(d[4][0], d[4][1], d[4][2])\n",
    "print('\\nMutual influence matrix:')\n",
    "prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of words in each level: [289 466 827 553 869 505]\n",
      "\n",
      "Standard deviation and mean difference matrix:\n",
      "[[0.32826869 1.3981321  1.43794338 1.63332216 1.76944473 1.75853892]\n",
      " [1.3981321  0.24800449 1.28503834 1.25316605 1.5057859  1.05397619]\n",
      " [1.43794338 1.28503834 0.20452765 0.84101285 0.70213442 1.30977094]\n",
      " [1.63332216 1.25316605 0.84101285 0.24863197 1.01251786 1.45819961]\n",
      " [1.76944473 1.5057859  0.70213442 1.01251786 0.19980222 1.5221591 ]\n",
      " [1.75853892 1.05397619 1.30977094 1.45819961 1.5221591  0.2436866 ]]\n",
      "\n",
      "Average / Max / Min of mean difference for cognitive levels at distance k:\n",
      "k = 1: 1.2117720507841834 1.5221591018036675 0.8410128544890878\n",
      "k = 2: 1.2128608643082242 1.4581996070198378 0.702134423723043\n",
      "k = 3: 1.4829596649214078 1.6333221581082449 1.3097709386315666\n",
      "k = 4: 1.411710464003241 1.7694447341009194 1.0539761939055627\n",
      "k = 5: 1.7585389201479138 1.7585389201479138 1.7585389201479138\n"
     ]
    }
   ],
   "source": [
    "# Expanded lists are core words unioned with newly classified words of the same domain.\n",
    "expanded_0 = knowledge_words\n",
    "expanded_1 = comprehension_words\n",
    "expanded_2 = application_words\n",
    "expanded_3 = analysis_words\n",
    "expanded_4 = synthesis_words\n",
    "expanded_5 = evaluation_words\n",
    "expanded_lists = [expanded_0, expanded_1, expanded_2, expanded_3, expanded_4, expanded_5]\n",
    "for word in list(result.keys()):\n",
    "    for i in range(6):\n",
    "        if result[word][str(i)]:\n",
    "            expanded_lists[i].append(word)\n",
    "virtual_sentences = ['' for i in range(6)]\n",
    "nlp_objs = []\n",
    "for i in range(6):\n",
    "    for word in expanded_lists[i]:\n",
    "        virtual_sentences[i] += word + ' '\n",
    "    nlp_objs.append(nlp(virtual_sentences[i]))\n",
    "\n",
    "# Initialization.\n",
    "vector_count = np.array([0 for i in range(6)])\n",
    "vector_mean = np.array([[0 for j in range(300)] for i in range(6)], dtype = np.float64)\n",
    "vector_dev = np.array([[0 for j in range(6)] for i in range(6)], dtype = np.float64)\n",
    "\n",
    "# The same thing done in BT 1 - Source verb analysis based on Word Embedding.ipynb, this time on the expanded lists.\n",
    "for i in range(6):\n",
    "    varsum = 0\n",
    "    for word in nlp_objs[i]:\n",
    "        if word.has_vector == True:\n",
    "            vector_mean[i] = vector_mean[i] + word.vector\n",
    "            vector_count[i] += 1\n",
    "    vector_mean[i] = vector_mean[i] / vector_count[i]\n",
    "    for word in nlp_objs[i]:\n",
    "        if word.has_vector == True:\n",
    "            diff = word.vector - vector_mean[i]\n",
    "            for entry in diff:\n",
    "                varsum += entry * entry\n",
    "    vector_dev[i][i] = np.sqrt(varsum) / vector_count[i]\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(i+1, 6):\n",
    "        varsum = 0\n",
    "        diff = vector_mean[i] - vector_mean[j]\n",
    "        for entry in diff:\n",
    "            varsum += entry * entry\n",
    "        vector_dev[i][j] = np.sqrt(varsum)\n",
    "        vector_dev[j][i] = vector_dev[i][j]\n",
    "\n",
    "d = np.array([[0 for j in range(3)] for i in range(5)], dtype = np.float64)\n",
    "for i in range(5):\n",
    "    for j in range(5 - i):\n",
    "        d[i][0] += vector_dev[j][j + i + 1]\n",
    "        if j == 0:\n",
    "            d[i][1] = vector_dev[j][j + i + 1]\n",
    "            d[i][2] = vector_dev[j][j + i + 1]\n",
    "        else:\n",
    "            d[i][1] = max(d[i][1], vector_dev[j][j + i + 1])\n",
    "            d[i][2] = min(d[i][2], vector_dev[j][j + i + 1])\n",
    "    d[i][0] /= (5 - i)\n",
    "    \n",
    "# Presentation of results.\n",
    "print('# of words in each level: ', end = '')\n",
    "print(vector_count)\n",
    "print('\\nStandard deviation and mean difference matrix:')\n",
    "print(vector_dev)\n",
    "print('\\nAverage / Max / Min of mean difference for cognitive levels at distance k:')\n",
    "print('k = 1: ', end = '')\n",
    "print(d[0][0], d[0][1], d[0][2])\n",
    "print('k = 2: ', end = '')\n",
    "print(d[1][0], d[1][1], d[1][2])\n",
    "print('k = 3: ', end = '')\n",
    "print(d[2][0], d[2][1], d[2][2])\n",
    "print('k = 4: ', end = '')\n",
    "print(d[3][0], d[3][1], d[3][2])\n",
    "print('k = 5: ', end = '')\n",
    "print(d[4][0], d[4][1], d[4][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
