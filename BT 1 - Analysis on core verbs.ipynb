{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "BT 1 - Source verb analysis based on Word Embedding.ipynb\n",
    "Author: Jingchuan Shi\n",
    "Acknowledgments: Asst. Prof. Ahmed Qureshi\n",
    "Created 2019/9/6, last modified 2019/9/17 at University of Alberta.\n",
    "All Rights Reserved.\n",
    "'''\n",
    "\n",
    "# Load relevant modules.\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_vectors\") # Model en_vectors_web_lg of SpaCy with a pre-defined shortcut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of words: 561\n",
      "# of words in each level: [ 54  69 133 121 118  66]\n",
      "\n",
      "Mean difference matrix for all words:\n",
      "[[0.         1.15502887 1.34243391 1.31132155 1.58943319 1.62824838]\n",
      " [1.15502887 0.         1.09023041 0.94523899 1.17300731 1.2951828 ]\n",
      " [1.34243391 1.09023041 0.         0.64854971 0.66654029 1.2129651 ]\n",
      " [1.31132155 0.94523899 0.64854971 0.         0.83013841 1.06498423]\n",
      " [1.58943319 1.17300731 0.66654029 0.83013841 0.         1.26755463]\n",
      " [1.62824838 1.2951828  1.2129651  1.06498423 1.26755463 0.        ]]\n",
      "\n",
      "Average / Max / Min of mean difference for cognitive levels at distance k (all words):\n",
      "k = 1: 0.9983004061053095 1.2675546309113535 0.6485497089239736\n",
      "k = 2: 1.004799357503706 1.3424339144864632 0.6665402948481126\n",
      "k = 3: 1.232431319336796 1.3113215461881553 1.1730073119238273\n",
      "k = 4: 1.4423079905346587 1.5894331860210271 1.2951827950482906\n",
      "k = 5: 1.6282483789073388 1.6282483789073388 1.6282483789073388\n",
      "\n",
      "Mean difference matrix for high frequency words:\n",
      "[[0.         2.35968682 2.62198908 2.68936412 3.12943409 2.60131916]\n",
      " [2.35968682 0.         2.00914257 2.05937894 2.78734937 2.21713143]\n",
      " [2.62198908 2.00914257 0.         2.33495036 2.29190402 2.54290237]\n",
      " [2.68936412 2.05937894 2.33495036 0.         3.04020187 2.47419871]\n",
      " [3.12943409 2.78734937 2.29190402 3.04020187 0.         3.09776449]\n",
      " [2.60131916 2.21713143 2.54290237 2.47419871 3.09776449 0.        ]]\n",
      "\n",
      "Average / Max / Min of mean difference for cognitive levels at distance k (high frequency words):\n",
      "k = 1: 2.5683492234421097 3.097764489691837 0.6485497089239736\n",
      "k = 2: 2.361867688621299 2.4741987143515027 0.6665402948481126\n",
      "k = 3: 2.6732052896504848 2.5429023729538534 1.1730073119238273\n",
      "k = 4: 2.673282757906625 2.2171314273579807 1.2951827950482906\n",
      "k = 5: 2.601319156678742 2.601319156678742 2.601319156678742\n",
      "\n",
      "Mean difference matrix for low frequency words:\n",
      "[[0.         1.2310329  1.39439508 1.37642295 1.57242263 1.69036545]\n",
      " [1.2310329  0.         1.13240039 1.03129245 1.13856824 1.4091128 ]\n",
      " [1.39439508 1.13240039 0.         0.62805    0.70264807 1.21930039]\n",
      " [1.37642295 1.03129245 0.62805    0.         0.76468352 1.05692001]\n",
      " [1.57242263 1.13856824 0.70264807 0.76468352 0.         1.12515027]\n",
      " [1.69036545 1.4091128  1.21930039 1.05692001 1.12515027 0.        ]]\n",
      "\n",
      "Average / Max / Min of mean difference for cognitive levels at distance k (low frequency words):\n",
      "k = 1: 0.9762634144466096 1.2675546309113535 0.6485497089239736\n",
      "k = 2: 1.0463139037080023 1.3424339144864632 0.6665402948481126\n",
      "k = 3: 1.2447638599093827 1.3113215461881553 1.1730073119238273\n",
      "k = 4: 1.4907677136095785 1.5894331860210271 1.2951827950482906\n",
      "k = 5: 1.6903654465678342 1.6903654465678342 1.6903654465678342\n"
     ]
    }
   ],
   "source": [
    "# The list of verbs pre-labelled with corresponding Bloom's Taxonomy domains.\n",
    "knowledge_words = nlp(r'list name define repeat state label recall identify reproduce describe recognize select record match relate memorize outline quote enumerate write tell recite cite duplicate read order tabulate draw review indicate underline arrange know point count collect meet study trace find index locate show visualize examine copy sequence acquire retell view observe tally imitate follow')\n",
    "comprehension_words = nlp(r'explain describe discuss paraphrase restate summarize translate convert review express estimate identify generalize interpret locate give distinguish extend predict recognize defend classify infer report illustrate rewrite select contrast differentiate compare indicate exemplify observe elaborate associate visualize articulate clarify subtract approximate interpolate tell detail outline cite picture interact conclude characterize add factor compute match schedule order sketch draw define operate arrange group extrapolate make_sense diagram interrelate represent trace shop suggest understand')\n",
    "application_words = nlp(r'demonstrate use apply solve illustrate dramatize practise employ operate sketch prepare show compute relate construct interpret discover change produce manipulate schedule modify predict complete choose classify translate determine examine calculate investigate draw write protect derive chart alphabetize simulate process provide capture project transcribe organize shop establish attain graph assign allocate convert experiment exercise diminish make develop ascertain tabulate depreciate subscribe implement handle transfer factor avoid expose express perform sequence acquire administer personalize adapt plot customize interview paint explore utilize report round_off figure price carry_out coordinate simplify consult maintain deliver extend imitate guide back_up conduct multiply build code contribute obtain model compare divide follow_up exhibit tally inform diagram expand amend engineer control assess concatenate execute convey articulate restructure criticize appraise participate generalize instruct follow act screen debate question select include dissect retrieve inspect prove inventory respond comply collect')\n",
    "analysis_words = nlp(r'compare contrast distinguish analyze differentiate separate examine diagram infer categorize experiment discriminate select appraise relate test question classify identify outline illustrate point out subdivide investigate debate criticize calculate inventory prioritize correlate explain inspect detect dissect manage audit characterize order deduce limit connect diagnose document proofread discover ensure optimize maximize confirm divide transform figure prepare file determine train size_up solve lay_out survey group minimize interrupt explore blueprint arrange query edit prove isolate reconcile troubleshoot sketch create summarize dramatize employ inquire link abstract establish organize compute devise set_up moderate delegate research model practise operate demonstrate schedule check use chunk choose scrutinize chart apply allow extrapolate recognize show modify administer review change monitor direct corroborate produce negotiate probe accept design interpret extract manipulate focus write predict resolve')\n",
    "synthesis_words = nlp(r'design create formulate plan compose construct develop combine assemble propose devise arrange organize collect rearrange prepare reconstruct invent generate modify write categorize rewrite relate compile revise reorganize set_up summarize manage generalize integrate explain produce originate tell incorporate facilitate hypothesize substitute specify improve format correspond model depict synthesize refer comply enhance import overhaul animate predict adapt cultivate code join handle anticipate portray express budget cope debug perform communicate outline prescribe initiate network program lecture dictate advise document gather derive abstract expand establish collaborate conduct contribute coordinate compare speculate simulate progress forecast instruct structure intervene frame measure estimate recommend negotiate consolidate choose contrast imagine individualize recognize solve roleplay review arbitrate teach supervise assess counsel exchange make_up brief reinforce unify pretend update validate')\n",
    "evaluation_words = nlp(r'judge appraise evaluate support assess select justify compare rate conclude value defend estimate choose critique argue measure recommend discriminate decide interpret criticize contrast rank predict explain summarize score grade revise relate verify test validate attach determine describe convince prescribe consider release counsel hire prioritize deduce enforce advise motivate core uphold resolve reconcile discuss authenticate review monitor weigh debate diagnose infer mediate prove use preserve access consolidate')\n",
    "wordlists = [knowledge_words, comprehension_words, application_words, analysis_words, synthesis_words, evaluation_words]\n",
    "knowledge_high = nlp(r'list name define repeat state label recall identify reproduce describe recognize select record')\n",
    "knowledge_low = nlp(r'match relate memorize outline quote enumerate write tell recite cite duplicate read order tabulate draw review indicate underline arrange know point count collect meet study trace find index locate show visualize examine copy sequence acquire retell view observe tally imitate follow')\n",
    "comprehension_high = nlp(r'explain describe discuss paraphrase restate summarize translate convert review express estimate identify generalize interpret locate give distinguish')\n",
    "comprehension_low = nlp(r'extend predict recognize defend classify infer report illustrate rewrite select contrast differentiate compare indicate exemplify observe elaborate associate visualize articulate clarify subtract approximate interpolate tell detail outline cite picture interact conclude characterize add factor compute match schedule order sketch draw define operate arrange group extrapolate make_sense diagram interrelate represent trace shop suggest understand')\n",
    "application_high = nlp(r'demonstrate use apply solve illustrate dramatize practise employ operate sketch prepare show compute relate construct interpret')\n",
    "application_low = nlp(r'discover change produce manipulate schedule modify predict complete choose classify translate determine examine calculate investigate draw write protect derive chart alphabetize simulate process provide capture project transcribe organize shop establish attain graph assign allocate convert experiment exercise diminish make develop ascertain tabulate depreciate subscribe implement handle transfer factor avoid expose express perform sequence acquire administer personalize adapt plot customize interview paint explore utilize report round_off figure price carry_out coordinate simplify consult maintain deliver extend imitate guide back_up conduct multiply build code contribute obtain model compare divide follow_up exhibit tally inform diagram expand amend engineer control assess concatenate execute convey articulate restructure criticize appraise participate generalize instruct follow act screen debate question select include dissect retrieve inspect prove inventory respond comply collect')\n",
    "analysis_high = nlp(r'compare contrast distinguish analyze differentiate separate examine diagram infer')\n",
    "analysis_low = nlp(r'categorize experiment discriminate select appraise relate test question classify identify outline illustrate point out subdivide investigate debate criticize calculate inventory prioritize correlate explain inspect detect dissect manage audit characterize order deduce limit connect diagnose document proofread discover ensure optimize maximize confirm divide transform figure prepare file determine train size_up solve lay_out survey group minimize interrupt explore blueprint arrange query edit prove isolate reconcile troubleshoot sketch create summarize dramatize employ inquire link abstract establish organize compute devise set_up moderate delegate research model practise operate demonstrate schedule check use chunk choose scrutinize chart apply allow extrapolate recognize show modify administer review change monitor direct corroborate produce negotiate probe accept design interpret extract manipulate focus write predict resolve')\n",
    "synthesis_high = nlp(r'design create formulate plan compose construct develop combine assemble propose devise arrange organize collect')\n",
    "synthesis_low = nlp(r'rearrange prepare reconstruct invent generate modify write categorize rewrite relate compile revise reorganize set_up summarize manage generalize integrate explain produce originate tell incorporate facilitate hypothesize substitute specify improve format correspond model depict synthesize refer comply enhance import overhaul animate predict adapt cultivate code join handle anticipate portray express budget cope debug perform communicate outline prescribe initiate network program lecture dictate advise document gather derive abstract expand establish collaborate conduct contribute coordinate compare speculate simulate progress forecast instruct structure intervene frame measure estimate recommend negotiate consolidate choose contrast imagine individualize recognize solve roleplay review arbitrate teach supervise assess counsel exchange make_up brief reinforce unify pretend update validate')\n",
    "evaluation_high = nlp(r'judge appraise evaluate support assess select justify compare rate conclude value defend estimate')\n",
    "evaluation_low = nlp(r'choose critique argue measure recommend discriminate decide interpret criticize contrast rank predict explain summarize score grade revise relate verify test validate attach determine describe convince prescribe consider release counsel hire prioritize deduce enforce advise motivate core uphold resolve reconcile discuss authenticate review monitor weigh debate diagnose infer mediate prove use preserve access consolidate')\n",
    "wordlists_high = [knowledge_high, comprehension_high, application_high, analysis_high, synthesis_high, evaluation_high]\n",
    "wordlists_low = [knowledge_low, comprehension_low, application_low, analysis_low, synthesis_low, evaluation_low]\n",
    "\n",
    "# Initialization.\n",
    "vector_count = np.array([0 for i in range(6)])\n",
    "total_count = 0\n",
    "vector_mean = np.array([[0 for j in range(300)] for i in range(6)], dtype = np.float64)\n",
    "vector_dev = np.array([[0 for j in range(6)] for i in range(6)], dtype = np.float64)\n",
    "high_count = np.array([0 for i in range(6)])\n",
    "high_mean = np.array([[0 for j in range(300)] for i in range(6)], dtype = np.float64)\n",
    "high_dev = np.array([[0 for j in range(6)] for i in range(6)], dtype = np.float64)\n",
    "low_count = np.array([0 for i in range(6)])\n",
    "low_mean = np.array([[0 for j in range(300)] for i in range(6)], dtype = np.float64)\n",
    "low_dev = np.array([[0 for j in range(6)] for i in range(6)], dtype = np.float64)\n",
    "\n",
    "# Compute vector averages.\n",
    "for i in range(6):\n",
    "    varsum = 0\n",
    "    for word in wordlists[i]:\n",
    "        if word.has_vector == True:\n",
    "            vector_mean[i] = vector_mean[i] + word.vector\n",
    "            vector_count[i] += 1\n",
    "            total_count += 1\n",
    "    vector_mean[i] = vector_mean[i] / vector_count[i]\n",
    "    for word in wordlists_high[i]:\n",
    "        if word.has_vector == True:\n",
    "            high_mean[i] = high_mean[i] + word.vector\n",
    "            high_count[i] += 1\n",
    "    high_mean[i] = high_mean[i] / high_count[i]\n",
    "    for word in wordlists_low[i]:\n",
    "        if word.has_vector == True:\n",
    "            low_mean[i] = low_mean[i] + word.vector\n",
    "            low_count[i] += 1\n",
    "    low_mean[i] = low_mean[i] / low_count[i]\n",
    "\n",
    "# Compute between-group differences.\n",
    "for i in range(6):\n",
    "    for j in range(i+1, 6):\n",
    "        varsum = 0\n",
    "        diff = vector_mean[i] - vector_mean[j]\n",
    "        for entry in diff:\n",
    "            varsum += entry * entry\n",
    "        vector_dev[i][j] = np.sqrt(varsum)\n",
    "        vector_dev[j][i] = vector_dev[i][j]\n",
    "        varsum = 0\n",
    "        diff = high_mean[i] - high_mean[j]\n",
    "        for entry in diff:\n",
    "            varsum += entry * entry\n",
    "        high_dev[i][j] = np.sqrt(varsum)\n",
    "        high_dev[j][i] = high_dev[i][j]\n",
    "        varsum = 0\n",
    "        diff = low_mean[i] - low_mean[j]\n",
    "        for entry in diff:\n",
    "            varsum += entry * entry\n",
    "        low_dev[i][j] = np.sqrt(varsum)\n",
    "        low_dev[j][i] = low_dev[i][j]\n",
    "        \n",
    "# Compare the mean differences between cognitive levels with respect to distance in levels.\n",
    "d_total = np.array([[0 for j in range(3)] for i in range(5)], dtype = np.float64)\n",
    "for i in range(5):\n",
    "    for j in range(5 - i):\n",
    "        d_total[i][0] += vector_dev[j][j + i + 1]\n",
    "        if j == 0:\n",
    "            d_total[i][1] = vector_dev[j][j + i + 1]\n",
    "            d_total[i][2] = vector_dev[j][j + i + 1]\n",
    "        else:\n",
    "            d_total[i][1] = max(d[i][1], vector_dev[j][j + i + 1])\n",
    "            d_total[i][2] = min(d[i][2], vector_dev[j][j + i + 1])\n",
    "    d_total[i][0] /= (5 - i)\n",
    "d_high = np.array([[0 for j in range(3)] for i in range(5)], dtype = np.float64)\n",
    "for i in range(5):\n",
    "    for j in range(5 - i):\n",
    "        d_high[i][0] += high_dev[j][j + i + 1]\n",
    "        if j == 0:\n",
    "            d_high[i][1] = high_dev[j][j + i + 1]\n",
    "            d_high[i][2] = high_dev[j][j + i + 1]\n",
    "        else:\n",
    "            d_high[i][1] = max(d[i][1], high_dev[j][j + i + 1])\n",
    "            d_high[i][2] = min(d[i][2], high_dev[j][j + i + 1])\n",
    "    d_high[i][0] /= (5 - i)\n",
    "d_low = np.array([[0 for j in range(3)] for i in range(5)], dtype = np.float64)\n",
    "for i in range(5):\n",
    "    for j in range(5 - i):\n",
    "        d_low[i][0] += low_dev[j][j + i + 1]\n",
    "        if j == 0:\n",
    "            d_low[i][1] = low_dev[j][j + i + 1]\n",
    "            d_low[i][2] = low_dev[j][j + i + 1]\n",
    "        else:\n",
    "            d_low[i][1] = max(d[i][1], low_dev[j][j + i + 1])\n",
    "            d_low[i][2] = min(d[i][2], low_dev[j][j + i + 1])\n",
    "    d_low[i][0] /= (5 - i)\n",
    "    \n",
    "# Presentation of results.\n",
    "print('Total # of words: ', end = '')\n",
    "print(total_count)\n",
    "print('# of words in each level: ', end = '')\n",
    "print(vector_count)\n",
    "print('\\nMean difference matrix for all words:')\n",
    "print(vector_dev)\n",
    "print('\\nAverage / Max / Min of mean difference for cognitive levels at distance k (all words):')\n",
    "print('k = 1: ', end = '')\n",
    "print(d_total[0][0], d_total[0][1], d_total[0][2])\n",
    "print('k = 2: ', end = '')\n",
    "print(d_total[1][0], d_total[1][1], d_total[1][2])\n",
    "print('k = 3: ', end = '')\n",
    "print(d_total[2][0], d_total[2][1], d_total[2][2])\n",
    "print('k = 4: ', end = '')\n",
    "print(d_total[3][0], d_total[3][1], d_total[3][2])\n",
    "print('k = 5: ', end = '')\n",
    "print(d_total[4][0], d_total[4][1], d_total[4][2])\n",
    "print('\\nMean difference matrix for high frequency words:')\n",
    "print(high_dev)\n",
    "print('\\nAverage / Max / Min of mean difference for cognitive levels at distance k (high frequency words):')\n",
    "print('k = 1: ', end = '')\n",
    "print(d_high[0][0], d_high[0][1], d_high[0][2])\n",
    "print('k = 2: ', end = '')\n",
    "print(d_high[1][0], d_high[1][1], d_high[1][2])\n",
    "print('k = 3: ', end = '')\n",
    "print(d_high[2][0], d_high[2][1], d_high[2][2])\n",
    "print('k = 4: ', end = '')\n",
    "print(d_high[3][0], d_high[3][1], d_high[3][2])\n",
    "print('k = 5: ', end = '')\n",
    "print(d_high[4][0], d_high[4][1], d_high[4][2])\n",
    "print('\\nMean difference matrix for low frequency words:')\n",
    "print(low_dev)\n",
    "print('\\nAverage / Max / Min of mean difference for cognitive levels at distance k (low frequency words):')\n",
    "print('k = 1: ', end = '')\n",
    "print(d_low[0][0], d_low[0][1], d_low[0][2])\n",
    "print('k = 2: ', end = '')\n",
    "print(d_low[1][0], d_low[1][1], d_low[1][2])\n",
    "print('k = 3: ', end = '')\n",
    "print(d_low[2][0], d_low[2][1], d_low[2][2])\n",
    "print('k = 4: ', end = '')\n",
    "print(d_low[3][0], d_low[3][1], d_low[3][2])\n",
    "print('k = 5: ', end = '')\n",
    "print(d_low[4][0], d_low[4][1], d_low[4][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
